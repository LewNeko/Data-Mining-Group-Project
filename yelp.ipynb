{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35d52fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/joenorton/nltk_data...\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/joenorton/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/joenorton/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Download the required resources\n",
    "nltk.download('wordnet')       # For lemmatization\n",
    "nltk.download('stopwords')     # For stop words\n",
    "nltk.download('punkt')         # For tokenization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7f6e06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16484, 5000)\n",
      "                                                text  \\\n",
      "0  I tweaked it a little, removed onions because ...   \n",
      "1  Bush used to have a white chili bean and it ma...   \n",
      "2  I have a very complicated white chicken chili ...   \n",
      "5  amazing! my boyfriend loved it so much! going ...   \n",
      "6  Wow!!!  This recipe is excellent as written!! ...   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0  tweaked little removed onion onion hater house...  \n",
      "1  bush used white chili bean made recipe super s...  \n",
      "2  complicated white chicken chili recipe made ye...  \n",
      "5       amazing boyfriend loved much going make week  \n",
      "6  wow recipe excellent written change made used ...  \n"
     ]
    }
   ],
   "source": [
    "# Step 1: Data Cleaning\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Load the dataset\n",
    "recipe_reviews_file_path = '/Users/joenorton/Desktop/DSA460/RecipeProject/Recipe Reviews and User Feedback Dataset.csv'  # Replace with your file path\n",
    "recipe_reviews_df = pd.read_csv(recipe_reviews_file_path)\n",
    "\n",
    "# Remove rows with 0 stars (indicating no reviews)\n",
    "recipe_reviews_cleaned_df = recipe_reviews_df[recipe_reviews_df['stars'] != 0]\n",
    "\n",
    "# Drop rows with any missing values in 'text' or 'stars' columns\n",
    "recipe_reviews_cleaned_df = recipe_reviews_cleaned_df.dropna(subset=['text', 'stars'])\n",
    "\n",
    "# Step 2: Text Preprocessing - Cleaning Text (removal of punctuation, stop words, and lemmatization)\n",
    "# Initialize the lemmatizer and stop words\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Clean text function: remove punctuation, stop words, and lemmatize\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()  # Convert to lowercase\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    words = text.split()  # Tokenize by whitespace\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stopwords.words('english')]  # Lemmatize and remove stop words\n",
    "    return \" \".join(words)\n",
    "\n",
    "# Apply the cleaning function to the 'text' column\n",
    "recipe_reviews_cleaned_df['cleaned_text'] = recipe_reviews_cleaned_df['text'].apply(clean_text)\n",
    "\n",
    "# Step 3: TF-IDF Vectorization with scikit-learn's built-in stopwords\n",
    "# Apply the TF-IDF vectorizer to the 'cleaned_text' data (with stopwords removal built into scikit-learn)\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')  # Limiting to top 5000 features\n",
    "\n",
    "# Apply the vectorizer to the cleaned text data\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(recipe_reviews_cleaned_df['cleaned_text'])\n",
    "\n",
    "# Step 4: Feature Normalization (Standard Scaling)\n",
    "scaler = StandardScaler(with_mean=False)  # Use with_mean=False because sparse matrices are used\n",
    "\n",
    "# Fit and transform the TF-IDF data\n",
    "X_scaled = scaler.fit_transform(X_tfidf)\n",
    "\n",
    "# The target variable is 'stars'\n",
    "y = recipe_reviews_cleaned_df['stars']\n",
    "\n",
    "# Display the shape of the transformed TF-IDF data and the first few rows of the cleaned text data\n",
    "print(X_scaled.shape)  # Output the shape of the TF-IDF feature matrix\n",
    "print(recipe_reviews_cleaned_df[['text', 'cleaned_text']].head())  # Display the cleaned text data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f653e1db",
   "metadata": {},
   "source": [
    "# Step 1: Data Cleaning\n",
    "\n",
    "Load the dataset\n",
    "\n",
    "Remove rows with 0 stars (indicating no reviews)\n",
    "\n",
    "Drop rows with any missing values in 'text' or 'stars' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399ca85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing rows with 0 stars:\n",
      "   Unnamed: 0  recipe_number  recipe_code         recipe_name  \\\n",
      "0           0              1        14299  Creamy White Chili   \n",
      "1           1              1        14299  Creamy White Chili   \n",
      "2           2              1        14299  Creamy White Chili   \n",
      "5           5              1        14299  Creamy White Chili   \n",
      "6           6              1        14299  Creamy White Chili   \n",
      "\n",
      "                                        comment_id         user_id  \\\n",
      "0  sp_aUSaElGf_14299_c_2G3aneMRgRMZwXqIHmSdXSG1hEM  u_9iFLIhMa8QaG   \n",
      "1  sp_aUSaElGf_14299_c_2FsPC83HtzCsQAtOxlbL6RcaPbY  u_Lu6p25tmE77j   \n",
      "2  sp_aUSaElGf_14299_c_2FPrSGyTv7PQkZq37j92r9mYGkP  u_s0LwgpZ8Jsqq   \n",
      "5  sp_aUSaElGf_14299_c_2Do918IutExN0pWEOFMU4cbiT8v  u_BALTQJIvWtYr   \n",
      "6  sp_aUSaElGf_14299_c_24hhcbywpsgGqG7yeDFH1IPZCb8  u_HuJVXMzQqJoI   \n",
      "\n",
      "    user_name  user_reputation  created_at  reply_count  thumbs_up  \\\n",
      "0     Jeri326                1  1665619889            0          0   \n",
      "1     Mark467               50  1665277687            0          7   \n",
      "2  Barbara566               10  1664404557            0          3   \n",
      "5     nikhita                1  1661354351            0          3   \n",
      "6   Sandy1256                1  1644088805            0         11   \n",
      "\n",
      "   thumbs_down  stars  best_score  \\\n",
      "0            0      5         527   \n",
      "1            0      5         724   \n",
      "2            0      5         710   \n",
      "5            1      5         518   \n",
      "6            0      5         833   \n",
      "\n",
      "                                                text  \n",
      "0  I tweaked it a little, removed onions because ...  \n",
      "1  Bush used to have a white chili bean and it ma...  \n",
      "2  I have a very complicated white chicken chili ...  \n",
      "5  amazing! my boyfriend loved it so much! going ...  \n",
      "6  Wow!!!  This recipe is excellent as written!! ...  \n",
      "\n",
      "After removing rows with missing 'text' or 'stars':\n",
      "   Unnamed: 0  recipe_number  recipe_code         recipe_name  \\\n",
      "0           0              1        14299  Creamy White Chili   \n",
      "1           1              1        14299  Creamy White Chili   \n",
      "2           2              1        14299  Creamy White Chili   \n",
      "5           5              1        14299  Creamy White Chili   \n",
      "6           6              1        14299  Creamy White Chili   \n",
      "\n",
      "                                        comment_id         user_id  \\\n",
      "0  sp_aUSaElGf_14299_c_2G3aneMRgRMZwXqIHmSdXSG1hEM  u_9iFLIhMa8QaG   \n",
      "1  sp_aUSaElGf_14299_c_2FsPC83HtzCsQAtOxlbL6RcaPbY  u_Lu6p25tmE77j   \n",
      "2  sp_aUSaElGf_14299_c_2FPrSGyTv7PQkZq37j92r9mYGkP  u_s0LwgpZ8Jsqq   \n",
      "5  sp_aUSaElGf_14299_c_2Do918IutExN0pWEOFMU4cbiT8v  u_BALTQJIvWtYr   \n",
      "6  sp_aUSaElGf_14299_c_24hhcbywpsgGqG7yeDFH1IPZCb8  u_HuJVXMzQqJoI   \n",
      "\n",
      "    user_name  user_reputation  created_at  reply_count  thumbs_up  \\\n",
      "0     Jeri326                1  1665619889            0          0   \n",
      "1     Mark467               50  1665277687            0          7   \n",
      "2  Barbara566               10  1664404557            0          3   \n",
      "5     nikhita                1  1661354351            0          3   \n",
      "6   Sandy1256                1  1644088805            0         11   \n",
      "\n",
      "   thumbs_down  stars  best_score  \\\n",
      "0            0      5         527   \n",
      "1            0      5         724   \n",
      "2            0      5         710   \n",
      "5            1      5         518   \n",
      "6            0      5         833   \n",
      "\n",
      "                                                text  \n",
      "0  I tweaked it a little, removed onions because ...  \n",
      "1  Bush used to have a white chili bean and it ma...  \n",
      "2  I have a very complicated white chicken chili ...  \n",
      "5  amazing! my boyfriend loved it so much! going ...  \n",
      "6  Wow!!!  This recipe is excellent as written!! ...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Load the dataset\n",
    "recipe_reviews_file_path = '/Users/joenorton/Desktop/DSA460/RecipeProject/Recipe Reviews and User Feedback Dataset.csv'\n",
    "recipe_reviews_df = pd.read_csv(recipe_reviews_file_path)\n",
    "\n",
    "# Remove rows with 0 stars (indicating no reviews)\n",
    "recipe_reviews_cleaned_df = recipe_reviews_df[recipe_reviews_df['stars'] != 0]\n",
    "print(\"After removing rows with 0 stars:\")\n",
    "print(recipe_reviews_cleaned_df.head())  # Display the cleaned data after removing rows with 0 stars\n",
    "\n",
    "# Drop rows with any missing values in 'text' or 'stars' columns\n",
    "recipe_reviews_cleaned_df = recipe_reviews_cleaned_df.dropna(subset=['text', 'stars'])\n",
    "print(\"\\nAfter removing rows with missing 'text' or 'stars':\")\n",
    "print(recipe_reviews_cleaned_df.head())  # Display the data after dropping rows with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f260813a",
   "metadata": {},
   "source": [
    "# Step 2: Text Preprocessing - Cleaning Text (removal of punctuation, stop words, and lemmatization)\n",
    "\n",
    "Initialize the lemmatizer and stop words\n",
    "\n",
    "Clean text function: remove punctuation, stop words, and lemmatize\n",
    "\n",
    "Apply the cleaning function to the 'text' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fe7806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After cleaning the text (removal of punctuation, stop words, and lemmatization):\n",
      "                                                text  \\\n",
      "0  I tweaked it a little, removed onions because ...   \n",
      "1  Bush used to have a white chili bean and it ma...   \n",
      "2  I have a very complicated white chicken chili ...   \n",
      "5  amazing! my boyfriend loved it so much! going ...   \n",
      "6  Wow!!!  This recipe is excellent as written!! ...   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0  tweaked little removed onion onion hater house...  \n",
      "1  bush used white chili bean made recipe super s...  \n",
      "2  complicated white chicken chili recipe made ye...  \n",
      "5       amazing boyfriend loved much going make week  \n",
      "6  wow recipe excellent written change made used ...  \n"
     ]
    }
   ],
   "source": [
    "# Initialize the lemmatizer and stop words\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Clean text function: remove punctuation, stop words, and lemmatize\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()  # Convert to lowercase\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    words = text.split()  # Tokenize by whitespace\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stopwords.words('english')]  # Lemmatize and remove stop words\n",
    "    return \" \".join(words)\n",
    "\n",
    "# Apply the cleaning function to the 'text' column\n",
    "recipe_reviews_cleaned_df['cleaned_text'] = recipe_reviews_cleaned_df['text'].apply(clean_text)\n",
    "print(\"\\nAfter cleaning the text (removal of punctuation, stop words, and lemmatization):\")\n",
    "print(recipe_reviews_cleaned_df[['text', 'cleaned_text']].head())  # Display the original and cleaned text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8c3a237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After TF-IDF Vectorization (first few TF-IDF features):\n",
      "(16484, 5000)\n",
      "Sample TF-IDF features: ['03' '10' '100' '1010' '1012' '1015' '1034' '105' '10min' '10x']\n"
     ]
    }
   ],
   "source": [
    "# Step 3: TF-IDF Vectorization with scikit-learn's built-in stopwords\n",
    "# Apply the TF-IDF vectorizer to the 'cleaned_text' data (with stopwords removal built into scikit-learn)\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')  # Limiting to top 5000 features\n",
    "\n",
    "# Apply the vectorizer to the cleaned text data\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(recipe_reviews_cleaned_df['cleaned_text'])\n",
    "print(\"\\nAfter TF-IDF Vectorization (first few TF-IDF features):\")\n",
    "print(X_tfidf.shape)  # Display the shape of the TF-IDF matrix\n",
    "print(\"Sample TF-IDF features:\", tfidf_vectorizer.get_feature_names_out()[:10])  # Display the first 10 TF-IDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33988077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After feature normalization (Standard Scaling):\n",
      "(16484, 5000)\n",
      "\n",
      "Final dataset for model training:\n",
      "                                                text  \\\n",
      "0  I tweaked it a little, removed onions because ...   \n",
      "1  Bush used to have a white chili bean and it ma...   \n",
      "2  I have a very complicated white chicken chili ...   \n",
      "5  amazing! my boyfriend loved it so much! going ...   \n",
      "6  Wow!!!  This recipe is excellent as written!! ...   \n",
      "\n",
      "                                        cleaned_text  stars  \n",
      "0  tweaked little removed onion onion hater house...      5  \n",
      "1  bush used white chili bean made recipe super s...      5  \n",
      "2  complicated white chicken chili recipe made ye...      5  \n",
      "5       amazing boyfriend loved much going make week      5  \n",
      "6  wow recipe excellent written change made used ...      5  \n",
      "Final preprocessed dataset saved to 'final_preprocessed_recipe_reviews.csv'\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Feature Normalization (Standard Scaling)\n",
    "scaler = StandardScaler(with_mean=False)  # Use with_mean=False because sparse matrices are used\n",
    "\n",
    "# Fit and transform the TF-IDF data\n",
    "X_scaled = scaler.fit_transform(X_tfidf)\n",
    "print(\"\\nAfter feature normalization (Standard Scaling):\")\n",
    "print(X_scaled.shape)  # Display the shape of the scaled features\n",
    "\n",
    "# The target variable is 'stars'\n",
    "y = recipe_reviews_cleaned_df['stars']\n",
    "\n",
    "# Display the final cleaned text and feature matrix shape\n",
    "print(\"\\nFinal dataset for model training:\")\n",
    "print(recipe_reviews_cleaned_df[['text', 'cleaned_text', 'stars']].head())  # Display final data\n",
    "\n",
    "final_df = recipe_reviews_cleaned_df[['text', 'cleaned_text', 'stars']]\n",
    "final_df.to_csv('final_preprocessed_recipe_reviews.csv', index=False)  # Save to CSV\n",
    "print(\"Final preprocessed dataset saved to 'final_preprocessed_recipe_reviews.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9d18647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with TF-IDF features saved to 'recipe_reviews_with_tfidf_features.csv'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (16484, 1), indices imply (16484, 5000)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m X_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(X_tfidf)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Create a DataFrame for the scaled features\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m X_scaled_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtfidf_vectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_feature_names_out\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Combine the scaled features with the original columns (text, stars, cleaned_text)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m combined_df_scaled \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([recipe_reviews_cleaned_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcleaned_text\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstars\u001b[39m\u001b[38;5;124m'\u001b[39m]], X_scaled_df], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/frame.py:867\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    859\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[1;32m    860\u001b[0m             arrays,\n\u001b[1;32m    861\u001b[0m             columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    864\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 867\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    876\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    877\u001b[0m         {},\n\u001b[1;32m    878\u001b[0m         index,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    881\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    882\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/internals/construction.py:336\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[1;32m    332\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[1;32m    333\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[1;32m    334\u001b[0m )\n\u001b[0;32m--> 336\u001b[0m \u001b[43m_check_values_indices_shape_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/internals/construction.py:420\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    418\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    419\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[0;32m--> 420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (16484, 1), indices imply (16484, 5000)"
     ]
    }
   ],
   "source": [
    "# Combine original columns (including 'text', 'stars', and 'cleaned_text') with the TF-IDF and scaled features\n",
    "# Reapply all previous transformations\n",
    "\n",
    "# Re-apply text preprocessing (if needed)\n",
    "recipe_reviews_cleaned_df['cleaned_text'] = recipe_reviews_cleaned_df['text'].apply(clean_text)\n",
    "\n",
    "# Apply the TF-IDF vectorizer to the 'cleaned_text' column\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(recipe_reviews_cleaned_df['cleaned_text'])\n",
    "\n",
    "# Create a DataFrame for the TF-IDF features\n",
    "X_tfidf_df = pd.DataFrame(X_tfidf.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Combine the TF-IDF features with the original columns (text, stars, cleaned_text)\n",
    "combined_df_tfidf = pd.concat([recipe_reviews_cleaned_df[['text', 'cleaned_text', 'stars']], X_tfidf_df], axis=1)\n",
    "\n",
    "# Save the dataframe with TF-IDF features to a CSV file\n",
    "combined_df_tfidf.to_csv('recipe_reviews_with_tfidf_features.csv', index=False)\n",
    "print(\"Data with TF-IDF features saved to 'recipe_reviews_with_tfidf_features.csv'\")\n",
    "\n",
    "# Apply feature scaling (standardization) to the TF-IDF features\n",
    "X_scaled = scaler.fit_transform(X_tfidf)\n",
    "\n",
    "# Create a DataFrame for the scaled features\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Combine the scaled features with the original columns (text, stars, cleaned_text)\n",
    "combined_df_scaled = pd.concat([recipe_reviews_cleaned_df[['text', 'cleaned_text', 'stars']], X_scaled_df], axis=1)\n",
    "\n",
    "# Save the dataframe with scaled features to a CSV file\n",
    "combined_df_scaled.to_csv('recipe_reviews_with_scaled_features.csv', index=False)\n",
    "print(\"Data with scaled features saved to 'recipe_reviews_with_scaled_features.csv'\")\n",
    "\n",
    "# Final dataset combining the cleaned text, stars, TF-IDF, and scaled features\n",
    "final_df = pd.concat([recipe_reviews_cleaned_df[['text', 'cleaned_text', 'stars']], X_scaled_df], axis=1)\n",
    "\n",
    "# Save the final preprocessed dataset with features to a CSV file\n",
    "final_df.to_csv('final_preprocessed_recipe_reviews_with_features.csv', index=False)\n",
    "print(\"Final preprocessed dataset with features saved to 'final_preprocessed_recipe_reviews_with_features.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf0b99cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final preprocessed dataset with features saved to 'final_preprocessed_recipe_reviews_with_features1.csv'\n",
      "   Unnamed: 0  recipe_number  recipe_code         recipe_name  \\\n",
      "0           0              1        14299  Creamy White Chili   \n",
      "1           1              1        14299  Creamy White Chili   \n",
      "2           2              1        14299  Creamy White Chili   \n",
      "5           5              1        14299  Creamy White Chili   \n",
      "6           6              1        14299  Creamy White Chili   \n",
      "\n",
      "                                        comment_id         user_id  \\\n",
      "0  sp_aUSaElGf_14299_c_2G3aneMRgRMZwXqIHmSdXSG1hEM  u_9iFLIhMa8QaG   \n",
      "1  sp_aUSaElGf_14299_c_2FsPC83HtzCsQAtOxlbL6RcaPbY  u_Lu6p25tmE77j   \n",
      "2  sp_aUSaElGf_14299_c_2FPrSGyTv7PQkZq37j92r9mYGkP  u_s0LwgpZ8Jsqq   \n",
      "5  sp_aUSaElGf_14299_c_2Do918IutExN0pWEOFMU4cbiT8v  u_BALTQJIvWtYr   \n",
      "6  sp_aUSaElGf_14299_c_24hhcbywpsgGqG7yeDFH1IPZCb8  u_HuJVXMzQqJoI   \n",
      "\n",
      "    user_name  user_reputation  created_at  reply_count  thumbs_up  \\\n",
      "0     Jeri326         0.001923  1665619889          0.0   0.000000   \n",
      "1     Mark467         0.096154  1665277687          0.0   0.066038   \n",
      "2  Barbara566         0.019231  1664404557          0.0   0.028302   \n",
      "5     nikhita         0.001923  1661354351          0.0   0.028302   \n",
      "6   Sandy1256         0.001923  1644088805          0.0   0.103774   \n",
      "\n",
      "   thumbs_down  stars  best_score  \\\n",
      "0     0.000000      5    0.557082   \n",
      "1     0.000000      5    0.765328   \n",
      "2     0.000000      5    0.750529   \n",
      "5     0.007937      5    0.547569   \n",
      "6     0.000000      5    0.880550   \n",
      "\n",
      "                                                text  \\\n",
      "0  I tweaked it a little, removed onions because ...   \n",
      "1  Bush used to have a white chili bean and it ma...   \n",
      "2  I have a very complicated white chicken chili ...   \n",
      "5  amazing! my boyfriend loved it so much! going ...   \n",
      "6  Wow!!!  This recipe is excellent as written!! ...   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0  i tweak it a littl remov onion becaus of onion...  \n",
      "1  bush use to have a white chili bean and it mad...  \n",
      "2  i have a veri complic white chicken chili reci...  \n",
      "5  amaz my boyfriend love it so much go to make i...  \n",
      "6  wow thi recip is excel as written the onli cha...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '/Users/joenorton/Desktop/DSA460/RecipeProject/Recipe Reviews and User Feedback Dataset.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Initialize stemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# Step 1: Drop rows with 0 stars\n",
    "df = df[df['stars'] != 0]\n",
    "\n",
    "# Step 2: Define text cleaning function (without stopword removal and lemmatization)\n",
    "def clean_text_stemming_only(text):\n",
    "    # Handle missing values (fill NaN with empty string)\n",
    "    if not isinstance(text, str):\n",
    "        text = \"\"\n",
    "    \n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "    # Split text into words manually (space-separated tokens)\n",
    "    words = text.split()\n",
    "\n",
    "    # Apply stemming\n",
    "    words = [ps.stem(word) for word in words]\n",
    "\n",
    "    # Join words back into a single string\n",
    "    cleaned_text = \" \".join(words)\n",
    "    return cleaned_text\n",
    "\n",
    "# Step 3: Apply text cleaning\n",
    "df['cleaned_text'] = df['text'].apply(clean_text_stemming_only)\n",
    "\n",
    "# Step 4: TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # Limit to 5000 features to avoid too large a matrix\n",
    "X_tfidf = vectorizer.fit_transform(df['cleaned_text'])\n",
    "\n",
    "# Step 5: Min-Max normalization on numerical features\n",
    "numerical_features = ['user_reputation', 'reply_count', 'thumbs_up', 'thumbs_down', 'best_score']\n",
    "scaler = MinMaxScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Save the final preprocessed dataset with features to a CSV file\n",
    "df.to_csv('final_preprocessed_recipe_reviews_with_features1.csv', index=False)\n",
    "print(\"Final preprocessed dataset with features saved to 'final_preprocessed_recipe_reviews_with_features1.csv'\")\n",
    "\n",
    "# Display a sample of the transformed data\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff875af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
